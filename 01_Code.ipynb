{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job title Classification by industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This notebook is directed to Eng. Ali Osama (Data Scientist at iNetworks)\n",
    "############### Multi-text Text Classification Task  #####################\n",
    "############### Job title Classification by industry #####################\n",
    "#By: Ahmed Ashraf Hussein - Machine Learning Intern applicant at iNetworks\n",
    "############### E-mail: s-ahmedashraf@zewailcity.edu.eg ##################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the essential libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## start of imports ############\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pickle as pic\n",
    "import request, json\n",
    "import requests\n",
    "############## End of imports  #############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure the csv file containing the data is located in the same directory as the notebook\n",
    "#if not, please provide the correct path in the next line of code\n",
    "df = pd.read_csv('Job titles and industries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "job title    0\n",
      "industry     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Quick check\n",
    "print (df.empty)                    #Ensuring that the dataframe is not empty\n",
    "print (df.isnull().sum())           #Ensuring that the dataframe has no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      industry  number_jobtitles\n",
      "0  Accountancy               374\n",
      "1    Education              1435\n",
      "2           IT              4746\n",
      "3    Marketing              2031\n",
      "\n",
      "The longest job title has 100 characters and the shortest has 2 characters\n"
     ]
    }
   ],
   "source": [
    "#Getting data insights\n",
    "\n",
    "counts = []\n",
    "industries = np.unique(df['industry'].values)\n",
    "for i in industries:\n",
    "    tot = sum(df['industry'] == i)\n",
    "    counts.append((i, tot))\n",
    "df_summary = pd.DataFrame(counts, columns=['industry', 'number_jobtitles'])\n",
    "print(df_summary)\n",
    "\n",
    "\n",
    "text_len = df['job title'].str.len()\n",
    "print(f'\\nThe longest job title has {text_len.max()} characters and the shortest has {text_len.min()} characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates that the job titles fall in 4 industries (Accountancy, Education, IT and Marketing) with the number of the instances in each industry to the right. The difference between that number in each industry indicates imbalanced data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = df.drop_duplicates()\n",
    "# counts = []\n",
    "# classes = np.unique(df2['industry'].values)\n",
    "# for i in classes:\n",
    "#     j = sum(df2['industry'] == i)\n",
    "#     counts.append((i, j))\n",
    "# df_stats = pd.DataFrame(counts, columns=['category', 'number_of_comments'])\n",
    "# df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "The commented section above was a trial to balance the data; by removing the duplicates from the data. It made a fairly good balance between the IT, Education and Marketing (1529,973,1203 respectively) but not the accountancy (263) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Data preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job title</th>\n",
       "      <th>industry_Accountancy</th>\n",
       "      <th>industry_Education</th>\n",
       "      <th>industry_IT</th>\n",
       "      <th>industry_Marketing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>technical support and helpdesk supervisor - co...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>senior technical support engineer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>head of it services</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>js front end engineer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>network and telephony controller</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job title  industry_Accountancy  \\\n",
       "0  technical support and helpdesk supervisor - co...                     0   \n",
       "1                  senior technical support engineer                     0   \n",
       "2                                head of it services                     0   \n",
       "3                              js front end engineer                     0   \n",
       "4                   network and telephony controller                     0   \n",
       "\n",
       "   industry_Education  industry_IT  industry_Marketing  \n",
       "0                   0            1                   0  \n",
       "1                   0            1                   0  \n",
       "2                   0            1                   0  \n",
       "3                   0            1                   0  \n",
       "4                   0            1                   0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting the industries to one hot encoding for faster processing\n",
    "#Accountancy    [1,0,0,0]\n",
    "#Education      [0,1,0,0]\n",
    "#IT             [0,0,1,0]\n",
    "#Marketing      [0,0,0,1]\n",
    "\n",
    "df['industry'] = pd.Categorical(df['industry'])\n",
    "dfDummies = pd.get_dummies(df['industry'], prefix = 'industry')\n",
    "df = pd.concat([df, dfDummies], axis=1)\n",
    "df = df.drop(['industry'], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two cells are to inspect the data, to get intuition about the job titles and develop the hand written rules can be used to clean the data. They display the longest job title(s), that can give the strongest indication about the normalization needed.\n",
    "The cell can be run repeatedly without affecting the original dataframe (df) that the developed rules would be applied on, eventually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = df.drop_duplicates()\n",
    "text_len2 = df2['job title'].str.len()\n",
    "len_sorted = sorted(text_len2, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4113    financial modeller / financial planning analys...\n",
      "567    java based graduate developer, central norwich...\n",
      "609    senior cro consultant - digital agency - londo...\n",
      "879    epos or pc or computer field service engineer ...\n",
      "609    senior cro consultant - digital agency - londo...\n",
      "879    epos or pc or computer field service engineer ...\n",
      "4948    marketing & sales assistant required - no expe...\n",
      "6786    graduate in maths - engineering - chemistry - ...\n",
      "4948    marketing & sales assistant required - no expe...\n",
      "6786    graduate in maths - engineering - chemistry - ...\n",
      "4411    regional marketing manager western europe- acu...\n",
      "7276    finance graduate/ trainee accountant role - st...\n",
      "4411    regional marketing manager western europe- acu...\n",
      "7276    finance graduate/ trainee accountant role - st...\n",
      "695     aem adobe consultant role: £100-120k basic sal...\n",
      "5333    content and digital marketing manager (part-ti...\n",
      "6278    education support officer: mathematics and num...\n",
      "695     aem adobe consultant role: £100-120k basic sal...\n",
      "5333    content and digital marketing manager (part-ti...\n",
      "6278    education support officer: mathematics and num...\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    #change the range of i to view different job titles\n",
    "    #starting from i=0 for the longest job titles and the bigger i the shortest the title\n",
    "    print(df2['job title'][text_len2 == len_sorted[i]].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cleaning and splitting The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definig a function for job titles cleaning\n",
    "def clean_jobtitles(text):\n",
    "    text = text.lower()                                 #converting all letters to lowercase\n",
    "    text = re.sub('\\W', ' ', text)                      #replacing all non words(e.g. £,/) by space\n",
    "    text = re.sub('(?<!^)\\d{2,}.+', ' ', text)          #removing digits and what's next as long as they don't start a jobtitle\n",
    "    text = re.sub('\\s+', ' ', text)                     #removing multiple white spaces\n",
    "    text = text.strip(' ')                              #stripping the text(assuring step)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['job title'] = df['job title'].map(lambda text : clean_jobtitles(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augmenting some words needed to be removed after noticed from the inspection cell above\n",
    "#those would be added to the predefined stopwords\n",
    "#those words (such as country names) could be removed by performing\n",
    "#named entity recognition or using dictionaries but this way is more effecient\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words = stop_words.union(['london','London','day','Day','days','Days','week','Week','weeks','Weeks','month','Month',\n",
    "                               'months','Months','year','Year','years','Years','role','Role','position',\n",
    "                               'Position','positions','Positions','required','Required','part','Part','time',\n",
    "                               'Time','full','Full','city','City','salary','Salary','starting','dubai','Dubai','uae',\n",
    "                               'early'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data by StratifiedShuffleSplit to manage imbalanced data\n",
    "spliter = StratifiedShuffleSplit(n_splits=5, test_size=0.25, random_state=0)\n",
    "X = df['job title']\n",
    "y = df.drop(['job title'], axis = 1)\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "for train_index, test_index in spliter.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a pipeline includes feature extractor and classifier\n",
    "pipeline_MNB = Pipeline([('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                         ('clf', OneVsRestClassifier(MultinomialNB(fit_prior=True, class_prior=None)))])\n",
    "#Model training\n",
    "pipeline_MNB.fit(X_train, y_train)\n",
    "\n",
    "#Model prediction\n",
    "prediction_MNB = pipeline_MNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB Accuracy Score equals 0.8872845831392641\n",
      "MNB F1 Score equals 0.911785799665312\n"
     ]
    }
   ],
   "source": [
    "#Model evaluation\n",
    "#we use different f1_score to assess imbalanced data\n",
    "print('MNB Accuracy Score equals '+str(accuracy_score(y_test, prediction_MNB)))\n",
    "print('MNB F1 Score equals '+str(f1_score(y_test, prediction_MNB, average='micro'))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a pipeline includes feature extractor and classifier\n",
    "pipeline_SVM = Pipeline([('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                         ('clf', OneVsRestClassifier(LinearSVC(), n_jobs=1))])\n",
    "#Model training\n",
    "pipeline_SVM.fit(X_train, y_train)\n",
    "#Model prediction\n",
    "prediction_SVM = pipeline_SVM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score equals 0.911970190964136\n",
      "SVM F1 Score equals 0.9295973628443608\n"
     ]
    }
   ],
   "source": [
    "#Model evaluation\n",
    "print('SVM Accuracy Score equals '+str(accuracy_score(y_test, prediction_SVM)))\n",
    "print('SVM F1 Score equals '+str(f1_score(y_test, prediction_SVM, average='micro'))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a pipeline includes feature extractor and classifier\n",
    "pipeline_LR = Pipeline([('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                         ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=1))])\n",
    "#Model training\n",
    "pipeline_LR.fit(X_train, y_train)\n",
    "#Model prediction\n",
    "prediction_LR = pipeline_LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Accuracy Score equals 0.8812296227293899\n",
      "LR F1 Score equals 0.9158607350096711\n"
     ]
    }
   ],
   "source": [
    "#Model evaluation\n",
    "print('LR Accuracy Score equals '+str(accuracy_score(y_test, prediction_LR)))\n",
    "print('LR F1 Score equals '+str(f1_score(y_test, prediction_LR, average='micro'))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the Model as a RESTful API service where the input is a HTTP request\n",
    "## with a parameter for the \"Job title\" and the output is the expected industry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we save the models to the storage. In the 'Flask.py' code, we can choose the desired model to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving models to disk\n",
    "pic.dump(pipeline_MNB, open('MNB_model.pkl','wb'))\n",
    "pic.dump(pipeline_SVM, open('SVM_model.pkl','wb'))\n",
    "pic.dump(pipeline_LR, open('LR_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions:\n",
    "1- open cmd\n",
    "2- run 'python Flask.py'\n",
    "3- provide the ip address to the url argument (first line in the next cell)\n",
    "4- change the value of 'exp' to test a new job title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted industry is Education\n"
     ]
    }
   ],
   "source": [
    "url = 'http://127.0.0.1:5000/api'\n",
    "r = requests.post(url,json={'exp':'teacher'})\n",
    "print(r.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
